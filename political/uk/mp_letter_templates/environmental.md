// Could have a shorter & longer version of this

// Two main points

1. Energy usage. 

// Better to under or over state this part? Cite the cambridge research or add some example calculations?

2. E-waste.

// Miners are special purpose computer hardware - cannot be reused for other purposes. They last 18 months (est 12000 tonnes of e-waste per year ##ref needed)

Emphasis that this impact is /by design/ it's not something which can be easilly solved 

It is not easy to put together an accurate estimate for exactly how much energy is expended securing the legders of proof of work crypto currencies, however upper and lower bounds can be found quite readily by calculating the average number calculations required to find a valid block at the current difficulty level and then using this number to work out how much computational power is being used. This can be translated into energy usage by looking at the most and least energy efficient hardware available for mining. 

At the time of writing, Cambridge University estimates the total energy usage to be 146 TWh per year, with upper and lower bounds of 503 TWh and 46 TWh. This is double the estimated usage for this time last year. For comparison Ireland used 184 TWh of energy during the whole of 2019 and the UK 2,178 TWh; Bitcoin alone uses more energy than many entire countries do, factoring in other less popular crypto currencies and this energy usage only continues to add up. This is not a problem which can be easilly solved, proof of work crypto currencies fundamentally rely on energy usage as their mechanism to secure the system - a reduction in energy usage means a reduction in security. The built in difficuly level means that even if a new more energy efficient piece of hardware was produced, over time the difficulty level would grow to compensate, negating any improvement. 

